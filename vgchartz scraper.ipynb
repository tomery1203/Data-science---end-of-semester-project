{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad267f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "sales_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_sales(name,fixed_name,console):\n",
    "   \n",
    "    #credit for soulution:https://towardsdatascience.com/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e\n",
    "    #note:couldnt pass 403 error\n",
    "    url='https://www.vgchartz.com/games/games.php?name='+fixed_name+'&keyword=&console='+console+'&region=All&developer=&publisher=&goty_year=&genre=&boxart=Both&banner=Both&ownership=Both&showmultiplat=No&results=50&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0&showvgchartzscore=0&shownasales=0&showdeveloper=0&showcriticscore=0&showpalsales=0&showreleasedate=0&showuserscore=0&showjapansales=0&showlastupdate=0&showothersales=0&showshipped=0&showshipped=1'\n",
    "    userAgent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=userAgent)\n",
    "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "   \n",
    "    if soup.find('tr',{'style':'background-image:url(../imgs/chartBar_large.gif); height:70px'}) is None:\n",
    "        sales_list.append(np.nan)\n",
    "        return\n",
    "    item=soup.find('tr',{'style':'background-image:url(../imgs/chartBar_large.gif); height:70px'}).find_all('td',{'align':'center'})\n",
    "        \n",
    "    total_shiped=item[1].get_text().strip()\n",
    "    \n",
    "    total_sales=item[2].get_text().strip()\n",
    "    \n",
    "    if total_sales != 'N/A':\n",
    "        \n",
    "        sales_list.append(float(total_sales[:-1]))\n",
    "        \n",
    "        return\n",
    "    if total_shiped !='N/A':\n",
    "        sales_list.append(float(total_shiped[:-1]))\n",
    "       \n",
    "        return\n",
    "    time.sleep(2)\n",
    "    return sales_list.append(np.nan)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb20ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('dataFrame#1.csv', index_col=0)\n",
    "df=modify_console_name(df)\n",
    "#chagne names of consoles to fit search of vgscripts search url.\n",
    "\n",
    "names=df['name'].tolist()\n",
    "dates=df['release date']\n",
    "consoles=df['platforms'].tolist()\n",
    "\n",
    "\n",
    "count=0\n",
    "for i in names:\n",
    "    if dates[count]=='TBA - Early Access':\n",
    "        #print('tba - early')\n",
    "        sales_list.append(np.nan)\n",
    "        count+=1\n",
    "        continue\n",
    "    \n",
    "    cons=consoles[count]\n",
    "    #print(i)\n",
    "    #print(dates[count])\n",
    "    date=int(dates[count].split(\",\")[1])\n",
    "    count+=1\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    else:\n",
    "        scrape_sales(i,(i.replace(\" \", \"+\")),cons)\n",
    "        \n",
    "        \n",
    "print(len(sales_list))\n",
    "df.insert(1,'total sales/mil',sales_list)\n",
    "df.to_csv('dataFrame#1.csv')\n",
    "display(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b8988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
