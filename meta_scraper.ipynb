{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'name':[], 'release date':[], 'developer': [], 'genre':[], 'rating':[], 'user rating':[],'age':[],'platforms':[],'number of players':[],'publisher':[]} # Data Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_each_game(url):#will scrape information from each game page\n",
    " \n",
    "    \n",
    "    \n",
    "    #credit for soulution:https://towardsdatascience.com/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e\n",
    "    #note:couldnt pass 403 error\n",
    "    \n",
    "    userAgent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=userAgent)\n",
    "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "    #print('-------------------------------------------------------------')\n",
    "    \n",
    "    #name################################################################################\n",
    "    \n",
    "    if soup.find('div', class_='product_title') is None:\n",
    "        return\n",
    "        \n",
    "    #print(name)\n",
    "    else: \n",
    "        name = soup.find('div', class_='product_title').find('h1').get_text()\n",
    "        data_dict['name'].append(name)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #platform#############################################################################\n",
    "    if soup.find('span', class_='platform') is None:\n",
    "        data_dict['platforms'].append(np.nan)\n",
    "    else:\n",
    "        platform = soup.find('span', class_='platform').get_text().strip()\n",
    "        #print(platform)\n",
    "        data_dict['platforms'].append(platform)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #release date#########################################################################\n",
    "    if soup.find('li',{\"class\":\"summary_detail release_data\"}).find(class_='data') is None:\n",
    "        data_dic['release date'].append(np.nan)\n",
    "    else:\n",
    "        release_date = soup.find('li',{\"class\":\"summary_detail release_data\"}).find(class_='data').get_text().strip()\n",
    "        #print(release_date)\n",
    "        data_dict['release date'].append(release_date)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #developer###########################################################################\n",
    "    developer = soup.find('li', class_='summary_detail developer')\n",
    "    if developer is not None:\n",
    "        developer = developer.find('span', class_='data').get_text().strip()\n",
    "        #print(developer)\n",
    "        data_dict['developer'].append(developer)\n",
    "    else:\n",
    "        developer = np.nan\n",
    "        #print(developer)\n",
    "        data_dict['developer'].append(developer)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #genre###############################################################################    \n",
    "    genre = []\n",
    "    for g in soup.find('li', class_='summary_detail product_genre').find_all('span', class_='data'): \n",
    "        genre.append(g.get_text().strip())\n",
    "       \n",
    "    lst='/'.join(genre)\n",
    "    #print(lst)\n",
    "    data_dict['genre'].append(lst)\n",
    "   \n",
    "\n",
    "\n",
    "    #rating##############################################################################\n",
    "    rating = soup.find('div', class_='details main_details').find('span',{'itemprop':'ratingValue'})\n",
    "    if rating is not None: \n",
    "        ratings = rating.get_text().strip()\n",
    "        data_dict['rating'].append(ratings)\n",
    "    else:\n",
    "        rating = np.nan\n",
    "        #print(rating)\n",
    "        data_dict['rating'].append(rating)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #user rating#########################################################################\n",
    "    user_rating=soup.find(class_='metascore_w user large game positive')\n",
    "    #note: metacritic devides ratings to colors\n",
    "    if user_rating is None:\n",
    "        user_rating=soup.find(class_='metascore_w user large game mixed')\n",
    "        if user_rating is None:\n",
    "            user_rating=soup.find(class_='metascore_w user large game negative')\n",
    "            if user_rating is None:\n",
    "                user_rating='-'\n",
    "    if user_rating=='-':\n",
    "        data_dict['user rating'].append(user_rating)\n",
    "    else: data_dict['user rating'].append(user_rating.get_text().strip())\n",
    "    #print(user_rating)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #age################################################################################\n",
    "    if soup.find(class_='summary_detail product_rating') is None:\n",
    "        age='-'\n",
    "    else:age=soup.find(class_='summary_detail product_rating').find(class_='data').get_text().strip()\n",
    "    data_dict['age'].append(age)\n",
    "    #print(age)\n",
    "    \n",
    "    \n",
    "    #number of players####################################################################\n",
    "    if soup.find(class_='summary_detail product_players') is None:\n",
    "        num_of_players='-'\n",
    "    else: num_of_players=soup.find(class_='summary_detail product_players').find(class_='data').get_text().strip()\n",
    "    data_dict['number of players'].append(num_of_players)\n",
    "    \n",
    "    if soup.find('li',{'class':'summary_detail publisher'})  is None:\n",
    "        data_dict['publisher'].append(np.nan)\n",
    "    else: \n",
    "        publish=soup.find('li',{'class':'summary_detail publisher'}).find('a',href=True).get_text().strip()\n",
    "        \n",
    "        data_dict['publisher'].append(publish)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11270d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_pages(response):#will calculate amount of pages to traverse\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pages = soup.find_all('li', {\"class\":\"page last_page\"})\n",
    "    pagesCleaned = pages[0].find('a', {\"class\":\"page_num\"})\n",
    "    return (pagesCleaned.text)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2900a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#lands on the first page of pc games filtered by highest score of metacritic.\n",
    "url = 'https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page=0'\n",
    "userAgent = {'User-agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=userAgent)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "\n",
    "amount_of_pages=int(how_many_pages(response))\n",
    "print(\"amount of pages:\",amount_of_pages)\n",
    "\n",
    "\n",
    "flag=0\n",
    "while flag < amount_of_pages: #casting string of how many pages to int.  \n",
    "   \n",
    "    for a in soup.find_all('a', {\"class\":\"title\"} ,href=True):\n",
    "        game_url='https://www.metacritic.com'+a['href']#sets the url to review page of the game. \n",
    "        scrape_each_game(game_url)\n",
    "       \n",
    "    time.sleep(1)    \n",
    "    flag+=1\n",
    "    #moves to next page:\n",
    "        #adds to the url the current page\n",
    "    url = 'https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page='+str(flag)\n",
    "    userAgent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=userAgent)\n",
    "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "    \n",
    "\n",
    "df=pd.DataFrame(data_dict) \n",
    "df.to_csv('dataFrame#1.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01774c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb58057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
